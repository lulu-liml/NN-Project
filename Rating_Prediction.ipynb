{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rating Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsNfVOGTyzTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io\n",
        "import json\n",
        "import random\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE6dya_IPhmG",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation\n",
        "Upload the dataset from Kaggle \n",
        "\n",
        "https://www.kaggle.com/jkgatt/restaurant-data-with-100-trip-advisor-reviews-each?select=factual_tripadvisor_restaurant_data_all_100_reviews.json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCfMWPl5zHN3",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "4d223b2f-7e17-4a23-c5d8-105dbc98c8c9"
      },
      "source": [
        "uploaded = files.upload()\n",
        "dataset = json.load(io.BytesIO(uploaded[\"factual_tripadvisor_restaurant_data_all_100_reviews.json\"]), encoding = \"utf-8\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e2d0fb09-b4a6-488c-84a8-27c4450e7199\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e2d0fb09-b4a6-488c-84a8-27c4450e7199\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving factual_tripadvisor_restaurant_data_all_100_reviews.json to factual_tripadvisor_restaurant_data_all_100_reviews.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZffkBe_KozI",
        "colab_type": "text"
      },
      "source": [
        "The dataset includes detail information of 147 restaurants, such as restaurant name, address, and phone number. For this project, we only focus on text reviews and numurial rating scores. Therefore, the customer reviews and ratings data for each restaurant are fetched and stored in a dataframe.\n",
        "\n",
        "Each restaurant has 100 customer rating scores and reviews. The *restaurant_id* in the dataframe *data* indicates which restaurant that review/score belongs to. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHrfvszRKel6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "2a164965-bbda-4574-d291-3b201140356e"
      },
      "source": [
        "reviews = []\n",
        "ratings = []\n",
        "restaurant_id = []\n",
        "num_of_restaurant = 147\n",
        "\n",
        "for i in range(num_of_restaurant):\n",
        "    score = 0\n",
        "    text = \"\"\n",
        "    count = 0\n",
        "    for review in dataset[\"restaurants\"][i][\"reviews\"]:\n",
        "        reviews.append(review[\"review_text\"])\n",
        "        ratings.append(review[\"review_rating\"])\n",
        "        restaurant_id.append(i)\n",
        "        count = count + 1\n",
        "\n",
        "data = pd.DataFrame(list(zip(ratings, reviews, restaurant_id)), columns =['Rating', 'Reviews', 'Restaurant_id']) \n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Restaurant_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>They have great local craft beers and probably...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>We went to the downtown SF location. The resta...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>I just came to this place for drinks with an o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Mediocre food (not bad, just mediocre, you can...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>We headed out for our team dinner to this esta...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14695</th>\n",
              "      <td>5</td>\n",
              "      <td>Try the chicken and waffles or the biscuit san...</td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14696</th>\n",
              "      <td>3</td>\n",
              "      <td>We have eaten here many times and have always ...</td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14697</th>\n",
              "      <td>5</td>\n",
              "      <td>The restaurant is hard to find unless you know...</td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14698</th>\n",
              "      <td>4</td>\n",
              "      <td>I stayed at the Farmer's Daughter hotel from A...</td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14699</th>\n",
              "      <td>3</td>\n",
              "      <td>So it is a pleasent place with an acomadating ...</td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14700 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Rating                                            Reviews  Restaurant_id\n",
              "0           4  They have great local craft beers and probably...              0\n",
              "1           4  We went to the downtown SF location. The resta...              0\n",
              "2           4  I just came to this place for drinks with an o...              0\n",
              "3           3  Mediocre food (not bad, just mediocre, you can...              0\n",
              "4           4  We headed out for our team dinner to this esta...              0\n",
              "...       ...                                                ...            ...\n",
              "14695       5  Try the chicken and waffles or the biscuit san...            146\n",
              "14696       3  We have eaten here many times and have always ...            146\n",
              "14697       5  The restaurant is hard to find unless you know...            146\n",
              "14698       4  I stayed at the Farmer's Daughter hotel from A...            146\n",
              "14699       3  So it is a pleasent place with an acomadating ...            146\n",
              "\n",
              "[14700 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBYJM4EAQC38",
        "colab_type": "text"
      },
      "source": [
        "The dataset is divided into a training set and a testing set. The testing set includes the reviews/scores of 30 randomly chosen restaurants. The rest of review data are in the training set, which will be used to train the nerual network. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODVQp7a3RHi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.DataFrame(columns={\"Rating\",\"Reviews\",\"Restaurant_id\"}) \n",
        "test_data = pd.DataFrame(columns={\"Rating\",\"Reviews\",\"Restaurant_id\"}) \n",
        "\n",
        "selected_restaurant = random.sample(list(np.unique(data[\"Restaurant_id\"])), int(num_of_restaurant*0.21))\n",
        "for i in range(num_of_restaurant):\n",
        "  if i not in selected_restaurant:\n",
        "    train_data = train_data.append(data.loc[data['Restaurant_id'] == i])\n",
        "  else:\n",
        "    test_data = test_data.append(data.loc[data['Restaurant_id'] == i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqnIc3eZUIB3",
        "colab_type": "text"
      },
      "source": [
        "The next step is to preprocess the textual review data. Digit, punctuation, multiple space, and stop words are filtered out. And all letters are in lowercase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCiQNxlERfnF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6d285eec-fddc-4276-b5e6-1f92386ee4ae"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "def text_preprocess(review):\n",
        "  review = re.sub(r'[^\\x00-\\x7F]+',' ', review)\n",
        "  # no digit\n",
        "  remove_digits = str.maketrans('', '', string.digits)\n",
        "  review = review.translate(remove_digits)\n",
        "  # no punctuation\n",
        "  review = review.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
        "  # low case\n",
        "  review = review.lower()\n",
        "  # no multiple space\n",
        "  review = re.sub(r'\\s+', ' ', review)\n",
        "  # no stop words\n",
        "  bagOfWords = review.split()\n",
        "  bagOfWords = [w for w in bagOfWords if not w in stop_words] \n",
        "  review = \" \".join(bagOfWords)\n",
        "  \n",
        "  return review\n",
        "\n",
        "#clean train set\n",
        "train_x = []\n",
        "train_y = list(train_data[\"Rating\"])\n",
        "train_id = list(train_data[\"Restaurant_id\"])\n",
        "train_text = list(train_data[\"Reviews\"])\n",
        "for i in train_text:\n",
        "  train_x.append(text_preprocess(i))\n",
        "\n",
        "#clean test set\n",
        "test_x = []\n",
        "test_y = list(test_data[\"Rating\"])\n",
        "test_id = list(test_data[\"Restaurant_id\"])\n",
        "test_text = list(test_data[\"Reviews\"])\n",
        "for i in test_text:\n",
        "  test_x.append(text_preprocess(i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_c1TlFZwUnL3",
        "colab_type": "text"
      },
      "source": [
        "The *Tokenizer* class in Keras is used to convert textual data into numerical data. And the length of each review string is set to be 100.\n",
        "\n",
        "The *fit_on_texts* method gives each vocabulary in total 5000 words an index based on its frequency occured in training dataset. A word with lower index indicates that the frequency of this word in the training set is higher.\n",
        "\n",
        "Then *texts_to_sequences* method transforms the training dataset and testing dataset into two sequences of integers by assigning the corresponding index value to each word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqxH_U4pUmXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words = 5000)\n",
        "tokenizer.fit_on_texts(train_x)\n",
        "\n",
        "train_x = tokenizer.texts_to_sequences(train_x)\n",
        "test_x = tokenizer.texts_to_sequences(test_x)\n",
        "\n",
        "max = 100\n",
        "train_x = pad_sequences(train_x, padding = 'post', maxlen = max)\n",
        "test_x = pad_sequences(test_x, padding = 'post', maxlen = max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKCvtZorbQQo",
        "colab_type": "text"
      },
      "source": [
        "# The Embedding Layer\n",
        "\n",
        "GloVe stands for global vectors for word representation, which is an unsupervised learning algorithm obtains vector representations for words. The training process of GloVe is to aggregating global word-word co-occurence matrix from a corpus. [1] \n",
        "\n",
        "In this project, a pre-trained word vector is used in the embedding layer. Different dimension (50d, 100d, 200d, 300d) of pre-trained word vector are choosen and applied in the neural network. The prediction performance after applying different dimension pre-trained word vectors will be compared."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkwBTl7MEVwz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "3aee6c47-289b-4561-c18d-1ac2306f9dfb"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-10 02:38:00--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-08-10 02:38:00--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-08-10 02:38:00--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.01MB/s    in 6m 27s  \n",
            "\n",
            "2020-08-10 02:44:27 (2.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj_996E5Eoc0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "39c0a78a-8df8-4df5-bbf7-da9bc46fcef7"
      },
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvE1eO3dEv2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "glove_dir = './'\n",
        "\n",
        "embeddings_index = {} \n",
        "\n",
        "#here we choose the 100d pre-trained word vector\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDvizMFvEw2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 100\n",
        "num_words = len(tokenizer.word_index) + 1\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim)) #create an array of zeros with word_num rows and embedding_dim columns\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if i < num_words:\n",
        "        if embedding_vector is not None:\n",
        "            # Words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdTnUy3DMooC",
        "colab_type": "text"
      },
      "source": [
        "# Feed Forward Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l0azxOwMvVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert the label into one-hot coding\n",
        "train_y = array(train_y)\n",
        "encoded_train_y = to_categorical(train_y)\n",
        "\n",
        "test_y = array(test_y)\n",
        "encoded_test_y = to_categorical(test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77349UxdJ9MT",
        "colab_type": "text"
      },
      "source": [
        "Input Layer -> Embedding Layer -> Dense Layer with Sigmoid activation function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGgiHuG-J6FM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dcac70ca-9498-4469-9c0b-73f58c101018"
      },
      "source": [
        "model = Sequential()\n",
        "layer = Embedding(num_words, embedding_dim, weights=[embedding_matrix], input_length = max, trainable = False)\n",
        "model.add(layer)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(6, activation='sigmoid'))\n",
        "model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['acc'])\n",
        "model.fit(train_x, encoded_train_y, batch_size = 200, epochs = 30, validation_split = 0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.1121 - acc: 0.4837 - val_loss: 0.0983 - val_acc: 0.5368\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0932 - acc: 0.5773 - val_loss: 0.0967 - val_acc: 0.5564\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0849 - acc: 0.6237 - val_loss: 0.0962 - val_acc: 0.5402\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0791 - acc: 0.6566 - val_loss: 0.0973 - val_acc: 0.5282\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0747 - acc: 0.6834 - val_loss: 0.0978 - val_acc: 0.5308\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0714 - acc: 0.7030 - val_loss: 0.0982 - val_acc: 0.5316\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0688 - acc: 0.7200 - val_loss: 0.0999 - val_acc: 0.5239\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0666 - acc: 0.7306 - val_loss: 0.1002 - val_acc: 0.5274\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0647 - acc: 0.7391 - val_loss: 0.1012 - val_acc: 0.5162\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0631 - acc: 0.7472 - val_loss: 0.1015 - val_acc: 0.5137\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0614 - acc: 0.7536 - val_loss: 0.1038 - val_acc: 0.4991\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0600 - acc: 0.7613 - val_loss: 0.1043 - val_acc: 0.5068\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0587 - acc: 0.7660 - val_loss: 0.1054 - val_acc: 0.5128\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0568 - acc: 0.7811 - val_loss: 0.1046 - val_acc: 0.5034\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0543 - acc: 0.7951 - val_loss: 0.1072 - val_acc: 0.4991\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0519 - acc: 0.8068 - val_loss: 0.1067 - val_acc: 0.5043\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0500 - acc: 0.8187 - val_loss: 0.1079 - val_acc: 0.5043\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0484 - acc: 0.8260 - val_loss: 0.1093 - val_acc: 0.5009\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0473 - acc: 0.8341 - val_loss: 0.1092 - val_acc: 0.5026\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0462 - acc: 0.8382 - val_loss: 0.1103 - val_acc: 0.4974\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0452 - acc: 0.8435 - val_loss: 0.1098 - val_acc: 0.4991\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0444 - acc: 0.8457 - val_loss: 0.1114 - val_acc: 0.4974\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0437 - acc: 0.8500 - val_loss: 0.1117 - val_acc: 0.4932\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0429 - acc: 0.8538 - val_loss: 0.1114 - val_acc: 0.4991\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.0423 - acc: 0.8549 - val_loss: 0.1118 - val_acc: 0.5000\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0418 - acc: 0.8586 - val_loss: 0.1136 - val_acc: 0.4983\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0410 - acc: 0.8628 - val_loss: 0.1128 - val_acc: 0.5043\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0406 - acc: 0.8646 - val_loss: 0.1138 - val_acc: 0.4932\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.0400 - acc: 0.8656 - val_loss: 0.1147 - val_acc: 0.4983\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.0395 - acc: 0.8670 - val_loss: 0.1148 - val_acc: 0.5051\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ffab8f39630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z1fEwBaQ1JA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "3b7b0b63-6f28-4076-89ea-9cdb1327b7fb"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 100, 100)          1883400   \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 60006     \n",
            "=================================================================\n",
            "Total params: 1,943,406\n",
            "Trainable params: 60,006\n",
            "Non-trainable params: 1,883,400\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bymShf8CLLfq",
        "colab_type": "text"
      },
      "source": [
        "Because this is not a classification problem, *R2* and *mean squared error* are used to measure the rating prediction performance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrgrZVe0LDDF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "33730c0e-76ca-4838-c7f9-bfbf7975a404"
      },
      "source": [
        "predict_restaurant_y = []\n",
        "actual_restaurant_y = []\n",
        "\n",
        "encoded_predict_y = model.predict(test_x)\n",
        "predict_y = np.argmax(encoded_predict_y, axis=1)\n",
        "\n",
        "sort = np.sort(selected_restaurant)\n",
        "for i in range(len(sort)):\n",
        "  p_y = sum(predict_y[i*100:(i+1)*100])\n",
        "  p_y = p_y/100\n",
        "  predict_restaurant_y.append(p_y)\n",
        "  a_y = sum(test_y[i*100:(i+1)*100])\n",
        "  a_y = a_y/100\n",
        "  actual_restaurant_y.append(a_y)\n",
        "\n",
        "print(\"R2: \"+ str(r2_score(test_y, predict_y)))\n",
        "print(\"mean_squared_error: \"+ str(mean_squared_error(test_y, predict_y)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2: -0.11385912554017152\n",
            "mean_squared_error: 1.0773333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzTn8HMeLuY5",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm6yViEJMDYG",
        "colab_type": "text"
      },
      "source": [
        "Input Layer -> Embedding Layer -> Convolutional Layer -> Pooling Layer -> Dense Layer with Sigmoid activation function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3_NCdPWL3yw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cec8d66d-b53c-452c-db5f-412a9d4c04d9"
      },
      "source": [
        "model = Sequential()\n",
        "layer = Embedding(num_words, embedding_dim, weights=[embedding_matrix], input_length = max, trainable = False)\n",
        "model.add(layer)\n",
        "model.add(Conv1D(embedding_dim, 5, activation = \"relu\"))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(6, activation='sigmoid'))\n",
        "model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['acc'])\n",
        "model.fit(train_x, encoded_train_y, batch_size = 200, epochs = 30, validation_split = 0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "53/53 [==============================] - 6s 122ms/step - loss: 0.1275 - acc: 0.4485 - val_loss: 0.0987 - val_acc: 0.5316\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 6s 120ms/step - loss: 0.1074 - acc: 0.4922 - val_loss: 0.0945 - val_acc: 0.5573\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 6s 120ms/step - loss: 0.1012 - acc: 0.5260 - val_loss: 0.0924 - val_acc: 0.5684\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 6s 121ms/step - loss: 0.0959 - acc: 0.5529 - val_loss: 0.0906 - val_acc: 0.5761\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 6s 121ms/step - loss: 0.0926 - acc: 0.5842 - val_loss: 0.0896 - val_acc: 0.5726\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 6s 120ms/step - loss: 0.0891 - acc: 0.6034 - val_loss: 0.0887 - val_acc: 0.5761\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 6s 122ms/step - loss: 0.0861 - acc: 0.6116 - val_loss: 0.0879 - val_acc: 0.5897\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 6s 121ms/step - loss: 0.0833 - acc: 0.6405 - val_loss: 0.0883 - val_acc: 0.5726\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 6s 121ms/step - loss: 0.0812 - acc: 0.6509 - val_loss: 0.0879 - val_acc: 0.5761\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 6s 120ms/step - loss: 0.0784 - acc: 0.6689 - val_loss: 0.0881 - val_acc: 0.5812\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 6s 120ms/step - loss: 0.0768 - acc: 0.6701 - val_loss: 0.0876 - val_acc: 0.5838\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 6s 120ms/step - loss: 0.0739 - acc: 0.6877 - val_loss: 0.0874 - val_acc: 0.5761\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 6s 121ms/step - loss: 0.0731 - acc: 0.6923 - val_loss: 0.0880 - val_acc: 0.5803\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 6s 121ms/step - loss: 0.0710 - acc: 0.7043 - val_loss: 0.0883 - val_acc: 0.5709\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 6s 120ms/step - loss: 0.0690 - acc: 0.7159 - val_loss: 0.0881 - val_acc: 0.5769\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 6s 121ms/step - loss: 0.0667 - acc: 0.7254 - val_loss: 0.0883 - val_acc: 0.5684\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 6s 120ms/step - loss: 0.0652 - acc: 0.7336 - val_loss: 0.0883 - val_acc: 0.5786\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 6s 121ms/step - loss: 0.0631 - acc: 0.7476 - val_loss: 0.0886 - val_acc: 0.5744\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 6s 120ms/step - loss: 0.0625 - acc: 0.7518 - val_loss: 0.0888 - val_acc: 0.5872\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 6s 120ms/step - loss: 0.0601 - acc: 0.7613 - val_loss: 0.0899 - val_acc: 0.5769\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 6s 120ms/step - loss: 0.0593 - acc: 0.7647 - val_loss: 0.0898 - val_acc: 0.5872\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 6s 121ms/step - loss: 0.0577 - acc: 0.7712 - val_loss: 0.0899 - val_acc: 0.5838\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 6s 121ms/step - loss: 0.0575 - acc: 0.7720 - val_loss: 0.0890 - val_acc: 0.5863\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 6s 121ms/step - loss: 0.0558 - acc: 0.7807 - val_loss: 0.0893 - val_acc: 0.5889\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 6s 121ms/step - loss: 0.0552 - acc: 0.7844 - val_loss: 0.0892 - val_acc: 0.5974\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 6s 120ms/step - loss: 0.0534 - acc: 0.7941 - val_loss: 0.0903 - val_acc: 0.5932\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 6s 120ms/step - loss: 0.0521 - acc: 0.8053 - val_loss: 0.0899 - val_acc: 0.5897\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 6s 120ms/step - loss: 0.0516 - acc: 0.8059 - val_loss: 0.0904 - val_acc: 0.5889\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 6s 120ms/step - loss: 0.0503 - acc: 0.8055 - val_loss: 0.0909 - val_acc: 0.5795\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 6s 121ms/step - loss: 0.0490 - acc: 0.8115 - val_loss: 0.0913 - val_acc: 0.5897\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ffab757a550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ujwdby4RFXr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "03385e45-3e06-4979-dcd8-de562b2a899a"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 100, 100)          1883400   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 96, 100)           50100     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 6)                 606       \n",
            "=================================================================\n",
            "Total params: 1,934,106\n",
            "Trainable params: 50,706\n",
            "Non-trainable params: 1,883,400\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pRL1n_zMp11",
        "colab_type": "text"
      },
      "source": [
        "Calculate the prediction performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI-j3l-fMsyF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fbe1950d-8872-4550-bac0-bc0d2df91426"
      },
      "source": [
        "predict_restaurant_y = []\n",
        "actual_restaurant_y = []\n",
        "\n",
        "encoded_predict_y = model.predict(test_x)\n",
        "predict_y = np.argmax(encoded_predict_y, axis=1)\n",
        "\n",
        "sort = np.sort(selected_restaurant)\n",
        "for i in range(len(sort)):\n",
        "  p_y = sum(predict_y[i*100:(i+1)*100])\n",
        "  p_y = p_y/100\n",
        "  predict_restaurant_y.append(p_y)\n",
        "  a_y = sum(test_y[i*100:(i+1)*100])\n",
        "  a_y = a_y/100\n",
        "  actual_restaurant_y.append(a_y)\n",
        "\n",
        "print(\"R2: \"+ str(r2_score(test_y, predict_y)))\n",
        "print(\"mean_squared_error: \"+ str(mean_squared_error(test_y, predict_y)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2: 0.12600657723704356\n",
            "mean_squared_error: 0.8453333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mKX2daLM48D",
        "colab_type": "text"
      },
      "source": [
        "# Recurrenct Neural Network (LSTM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkulxiviNA98",
        "colab_type": "text"
      },
      "source": [
        "Input Layer -> Embedding Layer -> LSTM Layer with 100 neurons -> Dense Layer with Sigmoid activation function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqSpjp7RNzKX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5cbeb756-3cee-4adc-e95d-c26948005e5e"
      },
      "source": [
        "model = Sequential()\n",
        "layer = Embedding(num_words, embedding_dim, weights=[embedding_matrix], input_length = max, trainable = False)\n",
        "model.add(layer)\n",
        "model.add(LSTM(100, dropout = 0.2, recurrent_dropout = 0.2))\n",
        "model.add(Dense(6, activation='sigmoid'))\n",
        "model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['acc'])\n",
        "model.fit(train_x, encoded_train_y, batch_size = 200, epochs = 30, validation_split = 0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "53/53 [==============================] - 28s 531ms/step - loss: 0.1335 - acc: 0.4843 - val_loss: 0.1003 - val_acc: 0.5316\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 28s 520ms/step - loss: 0.1054 - acc: 0.4923 - val_loss: 0.0993 - val_acc: 0.5316\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 28s 520ms/step - loss: 0.1053 - acc: 0.4924 - val_loss: 0.0994 - val_acc: 0.5316\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 29s 550ms/step - loss: 0.1051 - acc: 0.4929 - val_loss: 0.0990 - val_acc: 0.5316\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 28s 525ms/step - loss: 0.1052 - acc: 0.4925 - val_loss: 0.0989 - val_acc: 0.5325\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 28s 524ms/step - loss: 0.1049 - acc: 0.4930 - val_loss: 0.0993 - val_acc: 0.5299\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 28s 522ms/step - loss: 0.1045 - acc: 0.4953 - val_loss: 0.0987 - val_acc: 0.5308\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 28s 522ms/step - loss: 0.1031 - acc: 0.4967 - val_loss: 0.0967 - val_acc: 0.5291\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 28s 523ms/step - loss: 0.0985 - acc: 0.5229 - val_loss: 0.0944 - val_acc: 0.5564\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 28s 523ms/step - loss: 0.0947 - acc: 0.5478 - val_loss: 0.0887 - val_acc: 0.5966\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 28s 520ms/step - loss: 0.0910 - acc: 0.5734 - val_loss: 0.0874 - val_acc: 0.5923\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 28s 524ms/step - loss: 0.0899 - acc: 0.5790 - val_loss: 0.0892 - val_acc: 0.5752\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 28s 522ms/step - loss: 0.0872 - acc: 0.5918 - val_loss: 0.0861 - val_acc: 0.5957\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 28s 521ms/step - loss: 0.0866 - acc: 0.6024 - val_loss: 0.0859 - val_acc: 0.5897\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 28s 521ms/step - loss: 0.0847 - acc: 0.6114 - val_loss: 0.0851 - val_acc: 0.6077\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 28s 520ms/step - loss: 0.0842 - acc: 0.6106 - val_loss: 0.0849 - val_acc: 0.6128\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 28s 520ms/step - loss: 0.0825 - acc: 0.6212 - val_loss: 0.0837 - val_acc: 0.6137\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 27s 518ms/step - loss: 0.0817 - acc: 0.6223 - val_loss: 0.0855 - val_acc: 0.5923\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 28s 519ms/step - loss: 0.0798 - acc: 0.6378 - val_loss: 0.0846 - val_acc: 0.5983\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 28s 522ms/step - loss: 0.0803 - acc: 0.6380 - val_loss: 0.0845 - val_acc: 0.6111\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 28s 520ms/step - loss: 0.0791 - acc: 0.6425 - val_loss: 0.0846 - val_acc: 0.5974\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 27s 514ms/step - loss: 0.0778 - acc: 0.6527 - val_loss: 0.0852 - val_acc: 0.6034\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 28s 519ms/step - loss: 0.0773 - acc: 0.6562 - val_loss: 0.0839 - val_acc: 0.6094\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 27s 519ms/step - loss: 0.0763 - acc: 0.6636 - val_loss: 0.0840 - val_acc: 0.6154\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 28s 522ms/step - loss: 0.0742 - acc: 0.6721 - val_loss: 0.0853 - val_acc: 0.6034\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 29s 542ms/step - loss: 0.0739 - acc: 0.6741 - val_loss: 0.0862 - val_acc: 0.5932\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 28s 521ms/step - loss: 0.0723 - acc: 0.6840 - val_loss: 0.0869 - val_acc: 0.5974\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 28s 520ms/step - loss: 0.0719 - acc: 0.6889 - val_loss: 0.0874 - val_acc: 0.6085\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 28s 520ms/step - loss: 0.0720 - acc: 0.6859 - val_loss: 0.0884 - val_acc: 0.5889\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 28s 525ms/step - loss: 0.0703 - acc: 0.6983 - val_loss: 0.0902 - val_acc: 0.5949\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ffab5b7a668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNw3OSFSVjDN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "0d93d270-0222-4334-a64e-0594fdfebc54"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 100, 100)          1883400   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 6)                 606       \n",
            "=================================================================\n",
            "Total params: 1,964,406\n",
            "Trainable params: 81,006\n",
            "Non-trainable params: 1,883,400\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNvMgH8UN5BW",
        "colab_type": "text"
      },
      "source": [
        "Calculate the prediction performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJRKP_vNN4a2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8a1fb7e0-967b-450f-fc3b-868c7618e906"
      },
      "source": [
        "predict_restaurant_y = []\n",
        "actual_restaurant_y = []\n",
        "\n",
        "encoded_predict_y = model.predict(test_x)\n",
        "predict_y = np.argmax(encoded_predict_y, axis=1)\n",
        "sort = np.sort(selected_restaurant)\n",
        "for i in range(len(sort)):\n",
        "  p_y = sum(predict_y[i*100:(i+1)*100])\n",
        "  p_y = p_y/100\n",
        "  predict_restaurant_y.append(p_y)\n",
        "  a_y = sum(test_y[i*100:(i+1)*100])\n",
        "  a_y = a_y/100\n",
        "  actual_restaurant_y.append(a_y)\n",
        "\n",
        "print(\"R2: \"+ str(r2_score(test_y, predict_y)))\n",
        "print(\"mean_squared_error: \"+ str(mean_squared_error(test_y, predict_y)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2: 0.3417478558843664\n",
            "mean_squared_error: 0.6366666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29GkHuVaK7FQ",
        "colab_type": "text"
      },
      "source": [
        "# Reference\n",
        "[1]J. Pennington, GloVe: Global Vectors for Word Representation. [Online]. Available: https://nlp.stanford.edu/projects/glove/."
      ]
    }
  ]
}